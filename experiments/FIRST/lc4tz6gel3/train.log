INFO - 11/10/22 11:57:40 - 0:00:00 - ============ Initialized logger ============
INFO - 11/10/22 11:57:40 - 0:00:00 - cuda: False
                                     dico_build: S2T&T2S
                                     dico_eval: data/de-en.5000-6500.txt
                                     dico_max_rank: 10000
                                     dico_max_size: 0
                                     dico_method: csls_knn_10
                                     dico_min_size: 0
                                     dico_threshold: 0
                                     dico_train: data/de-en.0-5000.txt
                                     emb_dim: 300
                                     exp_id: 
                                     exp_name: FIRST
                                     exp_path: /u/halle/ralev/home_at/Desktop/Hiwi/multilingual-embeddings-anchors/MUSE/dumped/FIRST/lc4tz6gel3
                                     export: txt
                                     max_vocab: -1
                                     n_refinement: 5
                                     normalize_embeddings: 
                                     seed: -1
                                     src_emb: models/de_model_python.txt
                                     src_lang: de
                                     tgt_emb: models/en_model_python.txt
                                     tgt_lang: en
                                     verbose: 2
INFO - 11/10/22 11:57:40 - 0:00:00 - The experiment will be stored in /u/halle/ralev/home_at/Desktop/Hiwi/multilingual-embeddings-anchors/MUSE/dumped/FIRST/lc4tz6gel3
INFO - 11/10/22 11:57:45 - 0:00:05 - Loaded 90509 pre-trained word embeddings.
INFO - 11/10/22 12:03:04 - 0:05:24 - Loaded 2229285 pre-trained word embeddings.
